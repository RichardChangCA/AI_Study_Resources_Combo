1. Youtube Computer Vision Convolutional Neural Network(CNN) deeplearning.ai Andrew Ng: https://www.youtube.com/watch?v=ArPaAX_PhIs&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF

Convolution(1D,2D,3D), Pooling, ResNet, Inception, Transfer Learning, Data Augmentation, Object Detection, Sliding Windows, Intersection Over Union(IoU), Anchor Boxes, YOLO, Region Proposals, Face Recognition, Siamese Network, Face Verification, Style Transfer

2. Medium, Transfer Learning for Image Classification using Keras: https://towardsdatascience.com/transfer-learning-for-image-classification-using-keras-c47ccf09c8c8

3. Medium, Google Open Sources SimCLR, A Framework for Self-Supervised and Semi-Supervised Image Training: https://towardsdatascience.com/google-open-sources-simclr-a-framework-for-self-supervised-and-semi-supervised-image-training-72b06d5d58a0 ,this article may be not clear, but you can check the Paper: https://arxiv.org/abs/2002.05709 and the GitHub repo: https://github.com/google-research/simclr

4. Medium, Implementing a ResNet model from scratch: https://towardsdatascience.com/implementing-a-resnet-model-from-scratch-971be7193718 ，understanding resnet in detail

5. Medium, Face Detection in 10 lines for Beginners： https://towardsdatascience.com/face-detection-in-10-lines-for-beginners-1787aa1d9127 ，face, elbow, mouse detection by opencv lib in python

6. Youtube, Autoencoders - EXPLAINED: https://www.youtube.com/watch?v=7mRfwaGGAPg ,Mask Region based Convolution Neural Networks - EXPLAINED!(mask r-cnn): https://www.youtube.com/watch?v=4tkgOzQ9yyo ,this youtuber(CodeEmporium) explains concepts in a simple way: https://www.youtube.com/channel/UC5_6ZD6s8klmMu9TXEB_1IA

7. Medium, Understanding ResNet(winner in ILSVRC 2015): https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624 ,This residual architecture ensures the deeper model can outperform shallow models because the function of the residual block is F(x)=H(x)-x. If the model reaches the optima, F(x) will be 0, meaning residual connection can automatically determine the depth of deep learning models.

8. Medium, GoogLeNet(InceptionV1): https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7 ,idea: use 1*1 conv in middle, global avg pooling to replace FC layer, 1*1 conv can increase the effect of non-linearality as well as reduce the dimentionality of models(channels) to reduce computation. global avg pooling in the last layer can reduce number of weights and less prone to overfitting, intermediate softmax branches in inception model is used for training only(auxillary loss function), these intermediate softmax results are used in weighted loss function to tackle the problem of gradient vainishing(although it can be tackled well by ResNet).

9. Medium, InceptionV3 1st Runner Up (Image Classification) in ILSVRC 2015:  https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c ,inception v2 adds batch normalization based on inceptionv1 and inceptionv3 uses Factorizing Convolutions to reduce the number of parameters ,in addition, inceptionv3 uses grid size reduction to replace max pooling ,Auxiliary classifier in inceptionv3 is only used for regularization, moreover, Label Smoothing As Regularization

10. Medium, Review: MobileNetV1 — Depthwise Separable Convolution (Light Weight Model): https://towardsdatascience.com/review-mobilenetv1-depthwise-separable-convolution-light-weight-model-a382df364b69 MobileNet: MobileNet uses depthwise separable convolution to reduce the model size and complexity, which is a light-weight model. However, in most cases, depthwise separable convolution in MobileNet cannot perform better than the standard convolution. 

11. Medium, Review: VGGNet — 1st Runner-Up (Image Classification), Winner (Localization) in ILSVRC 2014 , https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11 , VGGNet uses 3*3 filters and multi-scale training & testing first(without fully connected layers), as well as replaces fully-connected layers with convolutional layers to improve the performance.

12. Medium, Review: Pre-Activation ResNet with Identity Mapping — Over 1000 Layers Reached (Image Classification)： https://towardsdatascience.com/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e ,pre-activation can ensure ResNet do clean identity mapping, this new ResNet can reach 1001 layers.

13. Medium, DenseNet — Dense Convolutional Network(CVPR 2017), https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803 ,while batch normalization can tackle the gradient vanishing & exploding, and deeper neural network is not overftting(overfitting is low bias and high variance), it is more likely a degradation, because deeper neural network training loss is higher than shallow neural network(higher bias) in plain neural networks. This is probably because the non-linear transformation lost the information of the original images, this is maybe why retnet works. Since this reason, Dense network works better than Resnet because each layer combines shallow features and higher features together.

14. Medium, Depth-wise Convolution and Depth-wise Separable Convolution: https://medium.com/@zurister/depth-wise-convolution-and-depth-wise-separable-convolution-37346565d4ec ,in computer vision, we use depth-wise conv more, but the problem of this is too much paramters(input channel*output channel*filter size*2), we can use depth-wise separable conv(1*1 conv after depth-wise conv) to reduce parameters(input channel*filter size*2 + input channel*output channel), this method also works well.

15. Medium, AlexNet, CaffeNet: https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160 ,AlexNet is a milestone architecture in deep learning, CaffeNet is a single-GPU version of AlexNet, some ideas in these two architectures are old-school.

16. Medium, SqueezeNet: https://towardsdatascience.com/review-squeezenet-image-classification-e7414825581a ,use fire model to squeeze model parameters.SqueezeNet can perform same as original models without squeezing. squeeze ratio set is another hyper-parameter to fine-tune. In this article, the complex bypass SqueezeNet performs worse than simple bypass SqueezeNet probably because only 1*1 conv cannot extract more contextual features as good as expanded (1*1, 3*3) conv sets.

17. Medium, Counting No. of Parameters in Deep Learning Models by Hand https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889 reduce the model size and training time with less parameters. predict whether your model is out of memory before training and determine suitable batch size. including cnn,rnn,mlp. You can know how to calculate feature maps in CNN models, cnn uses the most number of parameters and rnn uses the least number of parameters in common compared with these three models.

18. Medium & Paper, WRNs — Wide Residual Networks (Image Classification): https://towardsdatascience.com/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004 ,less layers(training faster) with higher accuracy but wider(more parameters). The problem of restnet is diminishing feature reuse, where a lot of blocks parameters in resnet cannot learn too much, a.k.a less gradient(other researchers randomly disable some blocks when training, similar to dropout). The idea of WRN is from "circuit complexity theory literature showing that shallow circuits can require exponentially more components than deeper circuits"  original paper: https://arxiv.org/pdf/1605.07146.pdf this paper WRN researched resnet a lot, including where use dropout, how much filter size should be used in blocks, pre-activation: conv-BN-ReLU to BN-ReLU-conv. Width in this article means number of channels, which is confused at first glance.

19. Medium, Inception V4: https://towardsdatascience.com/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc , combine new Inception v4 with Residual Inception v2 as ensemble learning to get a good result,  inception v4 has more inception models than inception v3.

20. Medium, Self-Attention In Computer Vision: https://towardsdatascience.com/self-attention-in-computer-vision-2782727021f6 ,use the idea from NLP to CV(including 3 paper ideas in this article), this idea is efficient maybe because "For radiologists, the experience in reading the images comes mostly from knowing where exactly to look in order to find a certain pathology". fuse local images(self-attention which part is important) and global images(whole image) together to do detection or classification, mask(self-attention) is generated according to the maximal values of different channels in feature maps and this mask can crop the original image to "self-attentioned" image. The first part of this articile uses the hard attention(either 0 or 1) not soft attention(range from 0-1). Since hard attention is not differentiable(cannot be trained), soft self-attention is used in Squeeze-And-Excitation-Networks, this model squeenze feature maps of the image into 1*1*channel (squeeze block)and use relu and sigmoid activation function(reduce dimentionality and expand) to find soft attention values for each global feature maps(channel-wise attention, excitation block). Shallow layer attention values are similar and deeper layer attention values are different, and this shows shallow layers can extract general features and deeper layers can extract specific features. The last article uses the idea of self-attention in NLP(K V Q), the brief idea of this model is transform the current "attention" to the most important part around its neighbors(a.k.a. "share weights" in paper, so this will lose the positional impormation of original images, and this problem is solved by position embedding). this papers visual self-attention is local attention(only consider its neighbors not whole feature maps).

21. Youtube, how to do bilinear interpolation in image upsampling: https://www.youtube.com/watch?v=q4-FJeWcidE ,linear interpolation in 2 dimensions by following a horizontal, vertical and center sequence.

22. Medium, A Walk-through of AlexNet, https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637 

23. Medium, 5 Awesome Projects to Hone Your Deep Learning Skills, https://towardsdatascience.com/5-awesome-projects-to-hone-your-deep-learning-skills-a2d6252b9b9b ,Implementing a convolutional neural network from scratch, Visual exploration of convolutional networks, Building an API for your deep learning model, Contributing to open source frameworks, Paper reproductions

24. Medium, Image Classification of X-Ray Scans, https://towardsdatascience.com/image-classification-of-x-ray-scans-ffaf970783f9 , VGG, data augmentation, binary classification

25. Medium, Face Identification: Siamese Convolutional Neural Nets, https://medium.com/@mark.s.cleverley/face-identification-siamese-convolutional-neural-nets-b4c66771595c ,Siamese Nets: twinned neural networks to identify whether two inputs are same or not. Suitable for the dataset which has limited images for each identity. Good idea(works well with fine-tuning) but poor result in this article.

26. Medium, Understanding Deep Self-attention Mechanism in Convolution Neural Networks, https://medium.com/datadriveninvestor/understanding-deep-self-attention-mechanism-in-convolution-neural-networks-e8f9c01cb251 ,covariance matrix, SAGAN: self-attention GAN

27. Medium, GAN for unsupervised anomaly detection on X-ray images. https://medium.com/vitalify-asia/gan-for-unsupervised-anomaly-detection-on-x-ray-images-6b9f678ca57d , have some issues in this method(just insights), Bi-directional GAN(encoder, generator, discriminator, discriminate between pair of data X and latent variable Z), AlphaGAN(combining autoencoder),

28. Medium, Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch), https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f ,original data, random noise, generator, discriminator, teach G to trick D and D to beware G, GAN are not stable.

29. Medium, Guide how to learn and master computer vision in 2020, https://towardsdatascience.com/guide-to-learn-computer-vision-in-2020-36f19d92c934 ,Albumentation(image augmentation framework), catalyst(high-level API on top of pytorch), Kaggle Kernels(30 hours/week free), Google Colab, Courses(Stanford CS231n, Fast.ai), paperswithcode, Kaggle Competitions provide many free open kernels. 

30. Medium, Brain Tumor Segmentation in MRI, https://medium.com/@prajbhumkar/brain-tumor-segmentation-in-mri-abc268faa304 ,MASK R-CNN, transfer learning based on COCO dataset

31. Medium, Analyze Knee MRIs with Python, https://towardsdatascience.com/deep-learning-and-medical-imaging-part-1-explore-the-mrnet-mri-dataset-of-knee-injuries-f519d063165 ,MRNet(knee MRI dataset), MRI scan, interactive plot

32. Medium, How to Train an MRI Classifier with PyTorch, https://medium.com/datadriveninvestor/deep-learning-and-medical-imaging-how-to-provide-an-automatic-diagnosis-f0138ea824d ,model architecture: MRNet, geometric transformations for data augmentation, To take into account the imbalanced nature of the classes, the loss of an example was scaled inversely proportionally to the prevalence of that example’s class in the dataset in order to penalize the error more on the least present examples. Accumulated gradients to prevent fluctuations in the loss.

33. Medium, Interpret What A Deep Learning Model Sees In Medical Imaging, https://medium.com/swlh/deep-learning-and-medical-imaging-interpret-what-the-model-sees-3a1a35b2a323 ,class activation map(weighted sum of the filters)

34. Medium, Build a simple Image Retrieval System with an Autoencoder, https://towardsdatascience.com/build-a-simple-image-retrieval-system-with-an-autoencoder-673a262b7921 ,autoencoder to encoder images + nearest neighbour algorithm to find similar images

35. Medium, Can AI Read Chest X-rays like Radiologists? adversarial network to segmentation. https://towardsdatascience.com/can-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff ,critic network to distinguish predicted mask from ground truth mask.

36. Medium, Complete Architectural Details of all EfficientNet Models, https://towardsdatascience.com/complete-architectural-details-of-all-efficientnet-models-5fd5b736142 ,baseline, width scaling(channel), depth scaling(layer), resolution scaling, compound scaling(combo)

37. Medium, Bye-bye MobileNet. Hello EfficientNet! https://towardsdatascience.com/bye-bye-mobilenet-hello-efficientnet-9b8ec2cc1a9c EfficientNet Lite model, Tensorflow Lite Package. EfficientNet-Lite-0 is slightly better than MobileNetV2 with slight larger amount of parameters, so slight trade-off model size and accuracy. 

38. Medium, Improving camera quality with Autoencoders, image super-resolution, https://towardsdatascience.com/improving-pewdiepies-camera-quality-with-autoencoders-583635de1cde ,high resolution images—>low resolution images: downscale and then upscale. 

39. Medium, Review: SENet — Squeeze-and-Excitation Network, Winner of ILSVRC 2017 (Image Classification), https://towardsdatascience.com/review-senet-squeeze-and-excitation-network-winner-of-ilsvrc-2017-image-classification-a887b98b2883 ,Squeeze-and-Excitation(SE) block that adaptively recalibrate channel-wise feature responses by explicitly modelling interdependencies between channels, Squeeze: Global information Embedding

40. Blog, A Gentle Introduction to Object Recognition With Deep Learning, https://machinelearningmastery.com/object-recognition-with-deep-learning/ ,object detection = image classification + object localization, R-CNN: Region Proposal —> Feature Extractor —> Classifier (downside: slow —> multi-stage pipeline & too many region proposals), Fast R-CNN: RoI project —> RoI Pooling layer —> bifurcate into two outputs for each RoI (Softmax for classification & bounding box regressor),  Faster R-CNN(anchor boxes): Region Proposal Network(reduce the number of region proposals) —> Fast R-CNN(The region proposal network acts as an attention mechanism for the Fast R-CNN network, informing the second network of where to look or pay attention). The R-CNN models may be generally more accurate, yet the YOLO family of models are fast, much faster than R-CNN, achieving object detection in real-time. YOLO: end-to-end neural network, split the input image into a grid of cells, where each cell is responsible for predicting a bounding box if the centre of a bounding box falls within it. YOLO_v2: Like Faster R-CNN, YOLOv2 model makes use of anchor boxes, pre-defined bounding boxes with useful shapes and sizes that are tailored during training. The choice of bounding boxes for the image is pre-processed using a k-means analysis on the training dataset. Anchor boxes: https://www.coursera.org/lecture/convolutional-neural-networks/anchor-boxes-yNwO0

41. Medium, Faster R-CNN (object detection) implemented by Keras for custom data from Google’s Open Images Dataset V4, https://towardsdatascience.com/faster-r-cnn-object-detection-implemented-by-keras-for-custom-data-from-googles-open-images-125f62b9141a ,GitHub: https://github.com/RockyXu66/Faster_RCNN_for_Open_Images_Dataset_Keras ,search selective to find out the regions of interests and passes them to a ConvNet, detailed information about the GitHub codes.

42. Medium, Splash of Color: Instance Segmentation with Mask R-CNN and TensorFlow, https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46 ,GitHub: https://github.com/matterport/Mask_RCNN ,ROI Pooling refers to cropping a part of a feature map and resizing it to a fixed size. ROIAlign: sample the feature map at different points and apply a bilinear interpolation, Mask R-CNN = Faster R-CNN + mask segmentation branch(lite because of the small size of bounding boxes), dataset annotation tools(LabelMe, RectLabel, LabelBox, VGG Image Annotator(VIA), COCO UI) 

43. Medium, Review: DeepMask (Instance Segmentation), https://towardsdatascience.com/review-deepmask-instance-segmentation-30327a072339 ,published in 2015, the first path is to predict the class-agnostic segmentation mask, the second path is to assign a score corresponding to how likely the patch is to contain an object. Region proposals are generated based on the predicted segmentation masks, which can be used as the first step of object detection task. Fast R-CNN using DeepMask outperforms original Fast R-CNN using Selective Search. 

44. Medium, Review: SharpMask — 1st Runner Up in COCO Segmentation 2015 (Instance Segmentation), https://towardsdatascience.com/review-sharpmask-instance-segmentation-6509f7401a61 ,published in 2016, encoder decoder architecture. DeepMask only coarsely align with the object boundaries, SharpMask produce sharper, pixel-accurate object masks. Two-stage training: the model is trained to jointly infer a coarse pixel-wise segmentation mask and an object score using the feedforward path. Second, the feedforward path is ‘frozen’ and the refinement modules trained. Paper: https://arxiv.org/pdf/1603.08695.pdf 

45. Medium, Review: PReLU-Net — The First to Surpass Human-Level Performance in ILSVRC 2015 (Image Classification), https://medium.com/coinmonks/review-prelu-net-the-first-to-surpass-human-level-performance-in-ilsvrc-2015-image-f619dddd5617 ,published on 2015, Parametric Rectified Linear Unit(PReLU), PReLU is suggested that there should be penalty for negative values and it should be parametric. A better weight initialization for rectifiers, Paper: https://arxiv.org/pdf/1502.01852.pdf ,PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. 

46. Medium, Review: PSPNet — Winner in ILSVRC 2016 (Semantic Segmentation / Scene Parsing), https://towardsdatascience.com/review-pspnet-winner-in-ilsvrc-2016-semantic-segmentation-scene-parsing-e089e5df177d ,Pyramid Scene Parsing Network. Semantic Segmentation is to know the category label of each pixels for known objects only. Scene Parsing ,which is based on Semantic Segmentation, is to know the category label of ALL pixels within the image. The need of global information to avoid mismatched relationship, confusion categories, inconspicuous classes. Auxiliary loss helps optimize the learning process. Paper: https://arxiv.org/pdf/1612.01105.pdf

47. Medium, Review: DeconvNet — Unpooling Layer (Semantic Segmentation), https://towardsdatascience.com/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e ,published on 2015 ICCV. To perform Unpooling, we need to remember the position of each maximum activation value when doing max pooling and then the remembered position is used for Unpooling as shown above. Paper: https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Noh_Learning_Deconvolution_Network_ICCV_2015_paper.pdf ,two stage training: space of semantic segmentation is large —> benefit to use a deconvolution network for instance-wise segmentation would be cancelled —> train the network with easy examples first and fine-tune the trained network with more challenging examples later —> first stage training: crop object instances using ground-truth annotations so that an object is entered at the cropped bounding box —> second stage: object proposals to construct training data makes the network more robust to the misalignment of proposals.

48. Medium, Review: ParseNet — Looking Wider to See Better (Semantic Segmentation)
, https://medium.com/datadriveninvestor/review-parsenet-looking-wider-to-see-better-semantic-segmentation-aa6b6a380990 ,published on 2016, global context can help to classify the local patches. The reason of having the L2 norm is that, because the earlier layers usually have larger values than the later layers. A learnable scaling factor gama for each channel is also introduced after normalization. Paper: https://arxiv.org/pdf/1506.04579.pdf 

49. Medium, Review: DRN — Dilated Residual Networks (Image Classification & Semantic Segmentation), https://towardsdatascience.com/review-drn-dilated-residual-networks-image-classification-semantic-segmentation-d527e1a8fb5 ,published on 2017 CVPR, GitHub: https://github.com/fyu/drn ,Paper: https://arxiv.org/pdf/1705.09914.pdf Dilated convolution + ResNet, gridding artifacts in dilation —> remove these artifacts(degridding): 1. Removing max pooling: max pooling operation leads to high-amplitude high-frequency activations and such high-frequency activations can be propagated to later layers and ultimately exacerbate gridding artifacts. 2. Adding layers with progressively lower dilation: add a 2-dilated residual block followed by a 1-dilated block and this is akin to removing aliasing artifacts using filters with appropriate frequency. 3. Removing residual connections: adding layers with decreasing dilation does not remove gridding artifacts entirely because of residual connections. Can be used in semantic segmentation. Keep high spatial resolution all the way through the final output layers. 

50. Medium, Review: Xception — With Depthwise Separable Convolution, Better Than Inception-v3 (Image Classification), https://towardsdatascience.com/review-xception-with-depthwise-separable-convolution-better-than-inception-v3-image-dc967dd42568 ,published on 2017 CVPR, depth-wise separable convolution —> channel-wise n*n spatial convolution followed by point-wise convolution(1*1 convolution). Modified depth-wise separable convolution in Xception(point-wise convolution followed by a depth-wise convolution and n=3 because of the structure of Inception-v3). Paper: https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf ,The presence or absence of a non-linearity after the first operation. In Inception, both operations are followed by a ReLU non-linearity, however depth-wise separable convolutions are usually implemented without non-linearities. The fundamental hypothesis behind Inception is that cross-channel correlations and spatial correlations are sufficiently decoupled that it is preferable not to map them jointly. A single convolution kernel is tasked with simultaneously mapping cross-channel correlations and spatial correlations. This idea behind the Inception module is to make this process easier and more efficient by explicitly factoring it into a series of operations that would independently look at cross-channel correlations and at spatial correlations. More precisely, the typical Inception module first looks at cross-channel correlations via a set of 1*1 convolutions, mapping the input data into 3 or 4 separate spaces that are smaller than the original input space, and then maps all correlations in these smaller 3D spaces, via regular 3*3 or 5*5 convolutions.

51. CNN Explainer, which is an interactive visualization tool to help beginners learn CNNs. Demo Video: https://www.youtube.com/watch?v=HnWIHWFbuUQ&feature=youtu.be Blog: https://poloclub.github.io/cnn-explainer/ ,YouTube Two Minute Papers Channel: https://www.youtube.com/watch?v=N6wn8zMRlVE ,GitHub: https://github.com/poloclub/cnn-explainer 

52. Medium, mAP (mean Average Precision) for Object Detection, https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173 ,the general definition for the Average Precision(AP) is finding the area under the precision-recall curve(x-axis: recall, y-axis: precision). mAP(mean average precision) is the average of AP. In some context, we compute the AP for each class and average them. But in some context, they mean the same thing. Under the COCO context, AP is averaged over all categories.

53. self-supervised learning: the basic idea is to automatically generate some kind of supervisory signal to solve some task. In deep learning, two patches are randomly selected and cropped from an unlabelled image and the goal is to predict the relative position of the two patches. AutoEncoders are self-supervised learning tools, but its more common to say that AEs are unsupervised learning tools, so SSL has also been used to refer to unsupervised learning techniques. 

54. Blog, CatGAN: cat face generation using GANs, https://hackernoon.com/catgan-cat-face-generation-using-gans-f44663586d6b ,use GAN to generate cat face draft image.

55. Medium, Understanding the mAP Evaluation Metric for Object Detection, https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3 ,the mean Average Precision or mAP score is calculated by taking the mean AP over all classes and/or over all IoU thresholds, depending on the competition. Code: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/cocoeval.py

56. Medium, Review: PyramidNet — Deep Pyramidal Residual Networks (Image Classification), https://medium.com/@sh.tsang/review-pyramidnet-deep-pyramidal-residual-networks-image-classification-85a87b60ae78 ,Gradually Increasing the Feature Map Dimensions, New Positions of ReLU and BN, Better Than DenseNet. 

57. Medium, A friendly introduction to Siamese Networks(With Pytorch codes demo), https://towardsdatascience.com/a-friendly-introduction-to-siamese-networks-85ab17522942 ,A Siamese Neural Network is a class of neural network architectures that contain two or more identical subnetworks. ‘Identical’ here means, they have the same configuration with the same parameters and weights. Parameter updating is mirrored across both sub-networks. It is used to find the similarity of the inputs by comparing its feature vectors, so these networks are used in many applications. Pros(More robust to class imbalance, nice to an ensemble with the best classifier, learning from semantic similarity.), Downsides(needs more training time than normal networks—invokes quadratic pairs to learn. Does not output probabilities). Triplet loss is a loss function where a baseline(anchor) input is compared to a positive(truthy) input and a negative(falsy) input. The distance from the baseline(anchor) input to the positive(truthy) input is minimized, and the distance from the baseline(anchor) input to the negative(falsy) input is maximized.

58. Medium, Knowledge Distillation : Simplified(Teacher Student Model), https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764 ,Knowledge distillation refers to the idea of model compression by teaching a smaller network, step by step, exactly what to do using a bigger already trained network. The ‘soft labels’ refer to the output feature maps by the bigger network after every convolution layer. The smaller network is then trained to learn the exact behaviour of the bigger network by trying to replicate its outputs at every level (not just the final loss). 

59. Medium, Image similarity using Triplet Loss, https://towardsdatascience.com/image-similarity-using-triplet-loss-3744c0f67973 ,For Triplet Loss, the objective is to build triplets<anchor, positive, negative> consisting of an anchor image, a positive image(which is similar to the anchor image) and a negative image(which is dissimilar to the anchor image), Triplet Loss architecture helps us to solve several problems having a very high number of classes.(face recognition)

60. Medium, Paper Explained- Vision Transformers (Bye Bye Convolutions?), https://medium.com/analytics-vidhya/vision-transformers-bye-bye-convolutions-e929d022e4ab ,Transformers work really well for NLP however they are limited by the memory and compute requirements of the expensive quadratic attention computation in the encoder block(image).

61. Youtube, Michigan online, deep learning for computer vision, Justin Johnson, https://www.youtube.com/watch?v=dJYGatp4SvA&list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r&index=1
Image Classification: performance metric: Top 5 accuracy, Algorithm predicts 5 labels for each image, one of them needs to be right. 
Few shot learning: each category has less images.
Nearest neighbour is bad because we can afford slow training, but we need fast testing.
K-Nearest Neighbour: Universal Approximation: as the number of training samples goes into infinity, nearest neighbour can represent any function.
Curse of dimensionality: For uniform coverage of space, number of training points needed grows exponentially with dimension.
Loss function also called objective function, cost function. Negative loss function sometimes called reward function, profit function, utility function, fitness function.
Cross-entropy Loss(multinomial Logistic Regression, softmax function): want to interpret raw classifier scores as probabilities.
Numeric gradient: approximate, slow, easy to write
Analytic gradient: exact, fast, error-prone
Computer Gradients: In practice, always use analytic gradient, but check implementation with numerical gradient, this is called a gradient check.
Linear classifier interactive tool: http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/
Saddle point in a problem during optimization, especially in high dimensions.
Universal Approximation: A neural network with one hidden layer can approximate any function f with arbitrary precision.
Generally speaking, convex functions are easy to optimize: can derive theoretical guarantees about converging to global minimum.
Most neural networks need non-convex optimization: few or no guarantees about convergence, empirically it seems to work anyway.
Receptive Fields in CNN
Batch normalization estimates depend on mini-batch and cannot do this at test-time. 
Batch normalization usually inserted after fully connected or convolutional layers, and before nonlinearity.
Batch normalization makes deep networks much easier to train, allows higher learning rates, faster convergence, networks become more robust to initialization, acts as regularization during training. Behaves differently during training and testing: this is a very common source of bugs.
Layer normalization for fully-connected networks in the feature dimension, same behaviour at train and test, used in RNNs, Transformers.
Instance normalization for convolutional networks in the spatial dimension, same behaviour at train and test.
Batch norm: average on batch and spatial dimension, Layer norm: average on feature and spatial dimension, Instance Norm: only average on spatial dimension.
Group normalization: split channel into some number of groups, and do layer normalization over subsets of channel dimensions.
AlexNet: 1. most of the memory usage is in the early convolution layers 2. Nearly all parameters are in the fully-connected layers 3. Most floating-point ops occur in the convolution layers.
ZFNet: a bigger version of AlexNet
Two 3*3 conv has same receptive field as a single 5*5 conv, but has fewer parameters and takes less computation.
GoogLeNet, compared with AlexNet, VGG and ZFNet, many innovations for efficiency, reduce parameter count, memory usage and computation. Stem network: at the start aggressively downsamples input. Inception module: local unit with parallel branches. Local structure repeated many times throughout the network. Use 1*1 “Bottleneck” layers to reduce channel dimension before expensive conv. No large FC layers at the end! Instead uses global average pooling to collapse spatial dimensions, and one linear layer to produce class scores.
Neural Architecture Search: One network(controller) outputs network architectures. Sample child networks from controller and train them. After training a batch of child networks, make a gradient step on controller network(Using policy gradient). Over time, controller learns to output good architectures. Very expensive, each gradient step on controller requires training a batch of child models. Original paper trained on 800 GPUs for 28 days! Followup work has focused on efficient search.
CUDA(NVIDIA only) write C-like code that runs directly on the GPU. 
In order to use TPUs(Google Tensor Processing Units), you have to use TensorFlow.
PyTorch: Fundamental Concepts: 1. Tensor: like a numpy array, but can run on GPU 2. Autograd: Package for building computational graphs out of Tensors, and automatically computing gradients 3. Module: A neural network layer; may store state or learnable weights.
Problem of Sigmoid activation function: 1. Saturated neurons “kill” the gradients 2. Sigmoid outputs are not zero-centered 3. exp() is a bit compute expensive. 
Problem of Tanh activation function: still kills gradients when saturated
ReLU activation function: does not saturate, very computationally efficient, converges much faster than sigmoid/tanh in practice(e.g. 6x), but not zero-centered, and an annoyance: the gradient when x=0(rarely, just choose one side). Dead ReLU problem: never activate ==> sometimes initialize ReLU neurons with slightly positive biases(e.g. 0.01).
Leaky ReLU: will not “die”
Parametric Rectifier(PReLU): max(ax, x), backprop into alpha(learnable parameter)
Exponential Linear Unit(ELU): all benefits of ReLU, closer to zero mean outputs, negative saturation regime compared with leaky ReLU, adds some robustness to noise. Computation requires exp().
Scaled Exponential Linear Unit(SELU): Scaled version of ELU that works better for deep networks “Self-Normalizing” property; can train deep SELU networks without BatchNorm.
Data preprocessing for images: standardization(whole images or channel-wise), testing uses training mean and std.
Regularization: Fractional Max Pooling(receptive field of pooling is randomized)
Regularization: Stochastic Depth(training: skip some residual blocks in ResNet, testing: use the whole network)
Regularization: Mixup(training: train on random blends of images, testing: use original images)
Consider dropout for large fully-connected layers
Batch normalization and data augmentation almost always a good idea
Try cutout and mixup especially for small classification datasets.
Learning rate decay: step, reduce learning rate at a few fixed points.
Cosine learning rate decay
Learning Rate Decay: Inverse Sqrt(spend more time on small learning rate) 
Choosing Hyper-parameters: Grid Search, choose several values for each hyper-parameter(often space choices log-linearly), evaluate all possible choices on this hyper-parameter grid.
Choosing Hyper-parameters: Random Search
Choosing Hyper-parameters steps: Step 1. Check initial loss: turn off weight decay, sanity check loss at initialization, Step 2.overfit a small sample: try to train to 100% training accuracy on a small sample of training data(~5-10 mini-batches); fiddle with architecture, learning rate, weight initialization. Turn off regularization. Loss not going down? Learning rate too low, bad initialization, loss explodes to influence or NaN? Learning rate too high, bad initialization. Step 3. Find LR that makes loss go down: use the architecture from the previous step, use all training data, turn on small weight decay, find a learning rate that makes the loss drop significantly within ~100 iterations. Good learning rate to try: 1e-1, 1e-2, 1e-3, 1e-4. Step 4. Coarse grid, train for ~1-5 epochs: choose a few values of learning rate and weight decay around what worked from step 3, train a few models for ~1-5 epochs. Step 5. Reine grid, train longer. Step 6. Look at learning curves. Step 7. GOTO step 5.
Model Ensembles: Tips and Tricks, instead of training independent models, use multiple snapshots(checkpoints) of a single model during training. (Cyclic learning rate schedules can make this work even better)
Model Ensembles: Tips and Tricks, instead of using actual parameter vector, keep a moving average of the parameter vector and use that at test time(Polyak averaging)
Data Parallelism: Copy Model on each GPU, split data, GPUs only communicate once per iteration, and only exchange grad params, sum, update.
Video classification(RNN): sequence of images —> label
Sequential processing of non-sequential data: classify images by taking a series of “glimpses”
Exploding gradients —> gradient clipping: scale gradients if its norm is too big.
RNN: works on Ordered Sequences, good at long sequences: after one RNN layer, h_t “see” the whole sequence. Not parallelizable: need to compute hidden states sequentially.
Self-attention: works on sets of vectors, good at long sequence: after one self-attention layer, each output “sees” all inputs. Highly parallel: each output can be computed in parallel, but very memory intensive.
Saliency map via occlusion: mask part of the image before feeding to CNN, check how much predicted probabilities change.
Saliency map via back-propagation: compute gradient of(unnormalized) class score with respect to image pixels, take absolute value and max over RGB channels.
Saliency Maps: segmentation without supervision
Markov Decision Process(MDP), Markov Property: The current state completely characterizes the state of the world. Rewards and next states depend only on current state, not history. Agent executes a policy pi giving distribution of actions conditioned on states. The value function at state s, is the expected cumulative reward from following the policy from state s. The Q function at state s and action a, is the expected cumulative reward from taking action a in state s and then following the policy.
Bellman Equation Intuition: After taking action a in state s, we get reward r and move to a new state s’. After that, the max possible reward we can get is max_a’ Q*(s’,a’). Idea: if we find a function Q(s,a) that satisfies the Bellman Euation, then it must be Q*. Deep Q-Learning: use Bellman equation as loss. Policy Gradients: Train a network pi_theta(a|s) that takes state as input, gives distribution over which action to take in that state. Use REINFORCE rule for computing gradients. Actor-Critic:Train an actor that predicts actions(like policy gradient) and a critic that predicts the future rewards we get from taking those actions. Model-based:Learn a model of the world’s state transition function P(s_t+1|s_t,a_t) and then use planning through the model to make decisions. Imitation Learning: Gather data about how experts perform in the environment, learn a function to imitate what they do(supervised learning approach). Inverse Reinforcement Learning: Gather data of experts performing in environment, learn a reward function that they seem to be optimizing, then use RL on that reward function. Adversarial Learning: Learn to fool a discriminator that classifies actions as real/fake.
Lottery Ticket Hypothesis: Within a random deep network is a good subnet that won the “initialization lottery”. 
LVIS: A Dataset for large Vocabulary Instance Segmentation.(Few-Shot Learning)
Self-Supervised Learning: Step1: Train a CNN on some “pretext task” that does not require labeled data. Step2: Fine-tune CNN on target task(hopefully using not much labeled data).

62. Medium, Reconstruct corrupted data using Denoising Autoencoder(Python code), https://medium.com/@garimanishad/reconstruct-corrupted-data-using-denoising-autoencoder-python-code-aeaff4b0958e

63. CS231n Convolutional Neural Networks for Visual Recognition, https://www.youtube.com/watch?v=lvoHnicueoE&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&index=14

<b>Lecture 14: Deep Reinforcement Learning</b>

The value function at state s, is the expected cumulative reward from following the policy from state s. The Q-value function at state s and action a, is the expected cumulative reward from taking action a in state s and then following the policy. Bellman equation: if the optimal state-action values for the next time-step Q*(s’,a’) are known, then the optimal strategy is to take the action that maximizes the expected value of r+gama*Q*(s’,a’). Actor-Critic Algorithm: combine Policy Gradients and Q-Learning by training both an actor(the policy) and a critic(the Q-function), the actor decides which action to take, and the critic tells the actor how good its action was and how it should adjust, also alleviates the task of the critic as it only has to learn the values of(state, action) pairs generated by the policy. 

<b>Lecture 16: Adversarial Examples and Adversarial Training</b>

Universal Approximator Theorem: Neural nets can represent either function. Training on adversarial examples is a good regularizer. Adversarially trained neural nets have the best empirical success rate on adversarial examples of any machine learning mode.
